#############################################
Model Performance Tuning in Ryzen AI Software
#############################################

This page provides some of the techniques to improve CNN model performance when deploying on the NPU.

1. Enabling compiler optimization
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Ryzen-AI software uses a ``vaip_config.json`` file to configure the Vitis AI Execution Provider. 

For CNN-based models, configuration ``opt_level`` can be used to enable advanced compiler optimization, which can improve model running efficiency on the NPU


.. code-block:: 

    "xcompilerAttrs": {
        ....
        ....
        "opt_level" : {
            "intValue" : 0
        },



The default value of ``opt_level`` is 0, which does not enable any compiler optimization. Set this to 1,2 or 3 to enable increasing levels of compiler optimizations, such as data-movement optimization, control path optimization, and operator fusion. 

- 0 (default): No advanced compiler optimization
- 1: Enable data movement optimization
- 2: Enable data movement and certain control path optimization; 
- 3: Enable data movement, control path, and operator fusion optimization


2. NPU subgraph control (experimental)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Ryzen-AI software uses a ``vaip_config.json`` file to configure the Vitis AI Execution Provider. 

For CNN-based models, configuration ``dpu_subgraph_num`` limits the maximum number of NPU subgraphs that can be created from the model compilation. The final, actual number of NPU subgraphs running on the NPU can be observed during the model run as shown below. 

.. code-block::

   ...
   [Vitis AI EP] No. of Subgraphs :   CPU     1    IPU     1 Actually running on IPU     1


If the user sees a large number of NPU subgraphs running on the NPU (but still less than default ``dpu_subgraph_num:intValue=32``), they can try to set ``dpu_subgraph_num:intValue`` to a lower number which can result in lesser number of NPU subgraphs, potentially alleviate slow model runtime performance.

On the other hand, If the NPU subgraphs generated by the compiler are more than the default ``dpu_subgraph_num:intValue=32``, then the whole model runs on the CPU. In this situation, the user can try to set ``dpu_subgraph_num:intValue`` to a larger number allowing a larger number of NPU subgraphs to run on NPU, thus saving CPU power, albeit it could run slow due to the increased number of NPU subgraphs. 

.. code-block::

    "xcompilerAttrs": {
     .....
     "dpu_subgraph_num" : {
     "intValue" : 32
     },


This configuration can only be used as an experimental trial.


.. note::
   In this documentation, "NPU" is used in descriptions, while "IPU" is retained in the tool's language, code, screenshots, and commands. This intentional distinction aligns with existing tool references and does not affect functionality. Avoid making replacements in the code.

..
  ------------

  #####################################
  License
  #####################################

 Ryzen AI is licensed under `MIT License <https://github.com/amd/ryzen-ai-documentation/blob/main/License>`_ . Refer to the `LICENSE File <https://github.com/amd/ryzen-ai-documentation/blob/main/License>`_ for the full license text and copyright notice.