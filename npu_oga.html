

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>OGA NPU Execution Mode &#8212; Ryzen AI Software 1.3 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/llm-table.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/rocm_header.css" />
    <link rel="stylesheet" type="text/css" href="_static/rocm_footer.css" />
    <link rel="stylesheet" type="text/css" href="_static/fonts.css" />
    <link rel="stylesheet" type="text/css" href="_static/_static/llm-table.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script async="async" src="https://download.amd.com/js/analytics/analyticsinit.js"></script>
    <script async="async" src="_static/code_word_breaks.js"></script>
    <script async="async" src="_static/renameVersionLinks.js"></script>
    <script async="async" src="_static/rdcMisc.js"></script>
    <script async="async" src="_static/theme_mode_captions.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'npu_oga';</script>
    <link rel="canonical" href="ryzenai.docs.amd.com/npu_oga.html" />
    <link rel="shortcut icon" href="https://www.amd.com/themes/custom/amd/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="google-site-verification" content="ZOn0RZC0Pwzlmf2SaE0bRttWk1YzOhuslbpxUDchQ90" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  

<header class="common-header" >
    <nav class="navbar navbar-expand-xl">
        <div class="container-fluid main-nav rocm-header">
            
            <button class="navbar-toggler collapsed" id="nav-icon" data-tracking-information="mainMenuToggle" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="header-logo">
                <a class="navbar-brand" href="https://www.amd.com/">
                    <img src="_static/images/amd-header-logo.svg" alt="AMD Logo" title="AMD Logo" width="90" class="d-inline-block align-text-top hover-opacity"/>
                </a>
                <div class="vr vr mx-40 my-25"></div>
                <a class="klavika-font hover-opacity" href="/">Ryzen AI</a>
            </div>
            <div class="icon-nav text-center d-flex ms-auto">
                <!-- TODO: Search icon up here maybe? -->
            </div>
        </div>
    </nav>
    
    <nav class="navbar navbar-expand-xl second-level-nav">
        <div class="container-fluid main-nav">
            <div class="navbar-nav-container collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-mega me-auto mb-2 mb-lg-0 col-xl-10">
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://github.com/vgodsoe/ryzen-ai-documentation" id="navgithub" role="button" aria-expanded="false" target="_blank" >
                                GitHub
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://community.amd.com/t5/ai/ct-p/amd_ai" id="navcommunity" role="button" aria-expanded="false" target="_blank" >
                                Community
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://www.amd.com/en/products/ryzen-ai" id="navproducts" role="button" aria-expanded="false" target="_blank" >
                                Products
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
    </nav>
    
</header>

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    <p class="title logo__title">Ryzen AI Software 1.3 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="relnotes.html">Release Notes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started on the NPU</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="inst.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime_setup.html">Runtime Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples, Demos, Tutorials</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Running CNNs on the NPU</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="modelcompat.html">Model Compatibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelport.html">Model Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="modelrun.html">Model Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="app_development.html">Application Development</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Running Models on the GPU</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="gpu/ryzenai_gpu.html">DirectML Flow</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Running LLMs on the NPU</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="llm/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/high_level_python.html">High-Level Python SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/server_interface.html">Server Interface (REST API)</a></li>
<li class="toctree-l1"><a class="reference internal" href="hybrid_oga.html">OGA API for C++ and Python</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Additional Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="xrt_smi.html">NPU Management Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="ai_analyzer.html">AI Analyzer</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Additional Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://huggingface.co/models?other=RyzenAI">Model Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="manual_installation.html">Manual Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses.html">Licensing Information</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-angle-right"></span>
  </label></div>
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">OGA NPU...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>OGA NPU Execution Mode</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-configurations">Supported Configurations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#requirements">Requirements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-performance-mode-optional">Setting performance mode (Optional)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#package-contents">Package Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-optimized-models">Pre-optimized Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#npu-execution-of-oga-models">NPU Execution of OGA Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-test-applications">Build the Test Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-environment-variables">Set the environment variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-models">Run the models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#run-using-a-batch-file">Run using a batch file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#run-manually">Run manually</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-benchmark">Run Benchmark</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Run using a batch file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Run manually</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-oga-models-for-npu-only-execution">Preparing OGA Models for NPU-only Execution</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="oga-npu-execution-mode">
<h1>OGA NPU Execution Mode<a class="headerlink" href="#oga-npu-execution-mode" title="Permalink to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Support for LLMs is currently in the Early Access stage. Early Access features are features which are still undergoing some optimization and fine-tuning. These features are not in their final form and may change as we continue to work in order to mature them into full-fledged features.</p>
</div>
<p>Starting with version 1.3, the Ryzen AI Software includes support for deploying LLMs on Ryzen AI PCs using the ONNX Runtime generate() API (OGA). This documentation is for the NPU execution of LLMs when using the OGA API.</p>
<section id="supported-configurations">
<h2>Supported Configurations<a class="headerlink" href="#supported-configurations" title="Permalink to this heading">#</a></h2>
<p>The Ryzen AI OGA flow supports the following processors running Windows 11:</p>
<ul class="simple">
<li><p>Strix (STX): AMD Ryzen™ Ryzen AI 9 HX375, Ryzen AI 9 HX370, Ryzen AI 9 365</p></li>
</ul>
<p><strong>Note</strong>: Phoenix (PHX) and Hawk (HPT) processors are not supported.</p>
</section>
<section id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>NPU Driver (version .237): Install according to the instructions <a class="reference external" href="https://ryzenai.docs.amd.com/en/latest/inst.html">https://ryzenai.docs.amd.com/en/latest/inst.html</a></p></li>
<li><p>NPU LLM artifacts package: <code class="docutils literal notranslate"><span class="pre">npu-llm-artifacts_1.3.0.zip</span></code> from <a class="reference external" href="https://account.amd.com/en/member/ryzenai-sw-ea.html">https://account.amd.com/en/member/ryzenai-sw-ea.html</a></p></li>
</ul>
</section>
<section id="setting-performance-mode-optional">
<h2>Setting performance mode (Optional)<a class="headerlink" href="#setting-performance-mode-optional" title="Permalink to this heading">#</a></h2>
<p>To run the LLMs in the best performance mode, follow these steps:</p>
<ul class="simple">
<li><p>Go to <code class="docutils literal notranslate"><span class="pre">Windows</span></code> → <code class="docutils literal notranslate"><span class="pre">Settings</span></code> → <code class="docutils literal notranslate"><span class="pre">System</span></code> → <code class="docutils literal notranslate"><span class="pre">Power</span></code> and set the power mode to Best Performance.</p></li>
<li><p>Execute the following commands in the terminal:</p></li>
</ul>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd C:\Windows\System32\AMD
xrt-smi configure --pmode performance
</pre></div>
</div>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this heading">#</a></h2>
<p>NPU LLM artifacts package contains the files required to build and run applications using the ONNX Runtime generate() API (OGA) to deploy LLMs on NPU. The list below describes which files are needed for the different use cases:</p>
<ul class="simple">
<li><p>C++ code to run LLM on NPU</p>
<ul>
<li><p>amd_oga/cpp/src/run_llm.cpp</p></li>
</ul>
</li>
<li><p>Runtime DLL and lib files in <code class="docutils literal notranslate"><span class="pre">amd_oga/libs</span></code></p>
<ul>
<li><p>onnxruntime.dll</p></li>
<li><p>onnxruntime_providers_shared.dll</p></li>
<li><p>onnxruntime_providers_vitisai.dll</p></li>
<li><p>onnxruntime_vitisai_ep.dll</p></li>
<li><p>onnxruntime_vitis_ai_custom_ops.dll</p></li>
<li><p>onnxruntime-genai.dll</p></li>
<li><p>dyn_dispatch_core.dll</p></li>
<li><p>transaction.dll</p></li>
<li><p>onnxruntime-genai.lib</p></li>
</ul>
</li>
<li><p>NPU binary file</p>
<ul>
<li><p>amd_oga/bins/xclbin/stx/llama2_mladf_2x4x4_v1_gemmbfp16_silu_mul_mha_rms_rope.xclbin</p></li>
</ul>
</li>
<li><p>Executables</p>
<ul>
<li><p>amd_oga/exe/run_llm.exe</p></li>
<li><p>amd_oga/exe/model_benchmark.exe</p></li>
</ul>
</li>
<li><p>Batch Files</p>
<ul>
<li><p>run.bat</p></li>
<li><p>run_benchmark.bat</p></li>
</ul>
</li>
<li><p>Python wheel files (Python 3.10)</p>
<ul>
<li><p>onnxruntime_genai-0.5.0.dev0-cp310-cp310-win_amd64.whl</p></li>
<li><p>onnxruntime_vitisai-1.20.0-cp310-cp310-win_amd64.whl</p></li>
<li><p>voe-1.3.1-cp310-cp310-win_amd64.whl</p></li>
</ul>
</li>
</ul>
</section>
<section id="pre-optimized-models">
<h2>Pre-optimized Models<a class="headerlink" href="#pre-optimized-models" title="Permalink to this heading">#</a></h2>
<p>AMD provides a set of pre-optimized LLMs ready to be deployed with Ryzen AI Software and the supporting runtime for NPU execution. These models can be found on Hugging Face in the following collection:</p>
<p><a class="reference external" href="https://huggingface.co/collections/amd/quark-awq-g128-int4-asym-bf16-onnx-npu-13-6759f510b8132db53e044aaf">https://huggingface.co/collections/amd/quark-awq-g128-int4-asym-bf16-onnx-npu-13-6759f510b8132db53e044aaf</a></p>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/amd/Phi-3-mini-4k-instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Phi-3-mini-4k-instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Phi-3.5-mini-instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Phi-3.5-mini-instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Mistral-7B-Instruct-v0.3-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Mistral-7B-Instruct-v0.3-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Qwen1.5-7B-Chat-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Qwen1.5-7B-Chat-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/chatglm3-6b-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/chatglm3-6b-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama2-7b-chat-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama2-7b-chat-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama-3-8B-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama-3-8B-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama-3.1-8B-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama-3.1-8B-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama-3.2-1B-Instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama-3.2-1B-Instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/amd/Llama-3.2-3B-Instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix">https://huggingface.co/amd/Llama-3.2-3B-Instruct-awq-g128-int4-asym-bf16-onnx-ryzen-strix</a></p></li>
</ul>
<p>The steps for deploying the pre-optimized models using C++ are described in the following sections.</p>
</section>
<section id="npu-execution-of-oga-models">
<h2>NPU Execution of OGA Models<a class="headerlink" href="#npu-execution-of-oga-models" title="Permalink to this heading">#</a></h2>
<section id="build-the-test-applications">
<h3>Build the Test Applications<a class="headerlink" href="#build-the-test-applications" title="Permalink to this heading">#</a></h3>
<p>NOTE: pre-built versions of the <code class="docutils literal notranslate"><span class="pre">run_llm.exe</span></code> and <code class="docutils literal notranslate"><span class="pre">model_generate.exe</span></code> executables are already available in the <code class="docutils literal notranslate"><span class="pre">amd_oga/exe</span></code> folder. If you choose to use them directly, you can skip to step 3 and copy the executables to <code class="docutils literal notranslate"><span class="pre">amd_oga/libs</span></code>. Otherwise follow the steps below to build the applications from source.</p>
<ol class="arabic simple">
<li><p>Open command prompt and navigate to the <code class="docutils literal notranslate"><span class="pre">amd_oga/cpp</span></code> folder</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Switch to cpp folder
cd amd_oga/cpp
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Compile</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cmake -G &quot;Visual Studio 17 2022&quot; -A x64 -S . -B build
cd build
cmake --build . --config Release
</pre></div>
</div>
<p><strong>Note</strong>: The executable created <code class="docutils literal notranslate"><span class="pre">run_llm.exe</span></code> and <code class="docutils literal notranslate"><span class="pre">model_generate.exe</span></code> can be found in <code class="docutils literal notranslate"><span class="pre">amd_oga/cpp/build/Release</span></code> folder</p>
<ol class="arabic simple" start="3">
<li><p>Copy the executables <code class="docutils literal notranslate"><span class="pre">run_llm.exe</span></code> and <code class="docutils literal notranslate"><span class="pre">model_generate.exe</span></code> to the <code class="docutils literal notranslate"><span class="pre">amd_oga/libs</span></code> folder. The <code class="docutils literal notranslate"><span class="pre">amd_oga/libs</span></code> should contain both: <code class="docutils literal notranslate"><span class="pre">run_llm.exe</span></code>, <code class="docutils literal notranslate"><span class="pre">model_benchmark.exe</span></code> along with the <code class="docutils literal notranslate"><span class="pre">.dll</span></code> files it contains.</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd amd_oga
xcopy .\cpp\build\Release\model_benchmark.exe .\libs
xcopy .\cpp\build\Release\run_llm.exe .\libs
</pre></div>
</div>
</section>
<section id="set-the-environment-variables">
<h3>Set the environment variables<a class="headerlink" href="#set-the-environment-variables" title="Permalink to this heading">#</a></h3>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>set DD_ROOT=./bins
set XLNX_ENABLE_CACHE=0
</pre></div>
</div>
</section>
<section id="run-the-models">
<h3>Run the models<a class="headerlink" href="#run-the-models" title="Permalink to this heading">#</a></h3>
<p><strong>Note</strong>: Ensure the models are cloned in the <code class="docutils literal notranslate"><span class="pre">amd_oga</span></code> folder.</p>
<section id="run-using-a-batch-file">
<h4>Run using a batch file<a class="headerlink" href="#run-using-a-batch-file" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">run.bat</span></code> batch file located in the <code class="docutils literal notranslate"><span class="pre">amd_oga</span></code> directory contains commands for running multiple models. If you wish to run only a specific model, you can do so by uncommenting the corresponding command and commenting out others.</p>
<p>For example, to run only Llama2-7b, ensure the line shown below is uncommented, and other commands are commented (preceded by REM).</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -f .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -c -t &quot;2048,1024,512,256,128&quot;
</pre></div>
</div>
<p>Run the models using run.bat:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Run the batch file
cd amd_oga
run.bat
</pre></div>
</div>
</section>
<section id="run-manually">
<h4>Run manually<a class="headerlink" href="#run-manually" title="Permalink to this heading">#</a></h4>
<p>To run the models using the <code class="docutils literal notranslate"><span class="pre">run_llm.exe</span></code> file</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd amd_oga
# Help
.\libs\run_llm.exe -h

# To enter prompt through command prompt, and default max new tokens
.\libs\run_llm.exe -m &lt;model_path&gt;

# For example,
.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix

# To provide max new tokens value which is set to 32 by default
.\libs\run_llm.exe -m &lt;model_path&gt; -n &lt;max_new_tokens&gt;

# For example,
.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -n 20

# To provide prompts through a prompt file
.\libs\run_llm.exe -m &lt;model_path&gt; -n &lt;max_new_tokens&gt; -f &lt;model_path&gt;\&lt;prompts.txt&gt;

# For example:
.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -n 20 -f .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt

# To use chat template
.\libs\run_llm.exe -m &lt;model_path&gt; -n &lt;max_new_tokens&gt; -f &lt;model_path&gt;\&lt;prompts.txt&gt; -c

# For example:
.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -n 20 -f .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -c

# To specify prompt length
.\libs\run_llm.exe -m &lt;model_path&gt; -n &lt;max_new_tokens&gt; -f &lt;model_path&gt;\&lt;prompts.txt&gt; -t &quot;list_prompt_lengths&quot;

# For example,

.\libs\run_llm.exe -m .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -n 20 -f .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -t &quot;2048,1024,512,256,128&quot;
</pre></div>
</div>
</section>
</section>
<section id="run-benchmark">
<h3>Run Benchmark<a class="headerlink" href="#run-benchmark" title="Permalink to this heading">#</a></h3>
<section id="id1">
<h4>Run using a batch file<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">run_benchmark.bat</span></code> batch file located in the <code class="docutils literal notranslate"><span class="pre">amd_oga</span></code> directory contains commands for running multiple models. If you wish to run only a specific model, you can do so by uncommenting the corresponding command and commenting out others.</p>
<p>For example, to run only Llama2-7b, ensure the line shown below is uncommented, and other commands are commented (preceded by REM).</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>.\libs\model_benchmark.exe -i .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -g 20 -p .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -l &quot;2048,1024,512,256,128&quot;
</pre></div>
</div>
<p>Run the models using run_benchmark.bat:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Run the batch file
cd amd_oga
run_benchmark.bat
</pre></div>
</div>
</section>
<section id="id2">
<h4>Run manually<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h4>
<p>To run the models using the <code class="docutils literal notranslate"><span class="pre">model_benchmark.exe</span></code> file</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd amd_oga
# Help
.\libs\model_benchmark.exe -h

# Run with default settings
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; -l &quot;list_of_prompt_lengths&quot;

# For example:
.\libs\model_benchmark.exe -i .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -p .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -l &quot;2048,1024,512,256,128&quot;

# To specify number of tokens to generate, default 128
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; -l &quot;list_of_prompt_lengths&quot; -g num_tokens

# For example:
.\libs\model_benchmark.exe -i .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix -g 20 -p .\Llama-2-7b-hf-awq-g128-int4-asym-bf16-onnx-ryzen-strix\prompts.txt -l &quot;2048,1024,512,256,128&quot;

# To specify number of warmup iterations before benchmarking, default: 1
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; -l &quot;list_of_prompt_lengths&quot; -w num_warmup

# To specify number of times to repeat the benchmark, default: 5
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; -l &quot;list_of_prompt_lengths&quot; -r num_iterations

# To specify sampling time interval for peak cpu utilization calculation, in milliseconds. Default: 250
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; -l &quot;list_of_prompt_lengths&quot; -t time_in_milliseconds

# To show more informational output
.\libs\model_benchmark.exe -i &lt;model_path&gt; -p &lt;model_path&gt;\&lt;prompts.txt&gt; --verbose
</pre></div>
</div>
</section>
</section>
</section>
<section id="preparing-oga-models-for-npu-only-execution">
<h2>Preparing OGA Models for NPU-only Execution<a class="headerlink" href="#preparing-oga-models-for-npu-only-execution" title="Permalink to this heading">#</a></h2>
<p>To prepare the OGA model for NPU-only execution please refer <span class="xref std std-doc">oga_model_prepare</span></p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-configurations">Supported Configurations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#requirements">Requirements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-performance-mode-optional">Setting performance mode (Optional)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#package-contents">Package Contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-optimized-models">Pre-optimized Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#npu-execution-of-oga-models">NPU Execution of OGA Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-test-applications">Build the Test Applications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-the-environment-variables">Set the environment variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-models">Run the models</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#run-using-a-batch-file">Run using a batch file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#run-manually">Run manually</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-benchmark">Run Benchmark</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Run using a batch file</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Run manually</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-oga-models-for-npu-only-execution">Preparing OGA Models for NPU-only Execution</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <p>
      Last updated on July 29, 2024.<br/>
  </p>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

<footer class="rocm-footer">
    <div class="container-lg">
        <section class="bottom-menu menu py-45">
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <ul>
                        <li><a href="https://www.amd.com/en/corporate/copyright" target="_blank">Terms and Conditions</a></li>
                        
                        <li><a href="">Ryzen AI Licenses and Disclaimers</a></li>
                        <li><a href="https://www.amd.com/en/corporate/privacy" target="_blank">Privacy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/trademarks" target="_blank">Trademarks</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf" target="_blank">Statement on Forced Labor</a></li>
                        <li><a href="https://www.amd.com/en/corporate/competition" target="_blank">Fair and Open Competition</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf" target="_blank">UK Tax Strategy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/cookies" target="_blank">Cookie Policy</a></li>
                        <!-- OneTrust Cookies Settings button start -->
                        <li><a href="#cookie-settings" id="ot-sdk-btn" class="ot-sdk-show-settings">Cookie Settings</a></li>
                        <!-- OneTrust Cookies Settings button end -->
                    </ul>
                </div>
            </div>
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <div>
                        <span class="copyright">© 2023 Advanced Micro Devices, Inc</span>
                    </div>
                </div>
            </div>
        </section>
    </div>
</footer>

<!-- <div id="rdc-watermark-container">
    <img id="rdc-watermark" src="_static/images/alpha-watermark.svg" alt="DRAFT watermark"/>
</div> -->
  </body>
</html>